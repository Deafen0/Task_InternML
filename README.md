set up: pip install -r requirements.txt
Launch: python -m streamlit run app.py   /use your python version 

For test text in English about Space Industry summary(facebook/bart-large-cnn):
The journey to space began in the minds of visionary thinkers and writers. The history of space exploration is not just a tale of technological achievement. It is a grand, multi-generational saga of humanambition, fierce geopolitical rivalry, breathtaking scientific discovery.

Why this models:
1. Локальные модели (facebook/bart-large-cnn и cointegrated/rut5-base-multitask)

Это модели, которые загружаются и запускаются непосредственно на машине, где работает приложение.

Почему они нужны?

    Бесплатно: Нет необходимости платить за каждый запрос, как в случае с API. Нужно только один раз скачать модель.

    Конфиденциальность: Текст пользователя не покидает его компьютер (или сервер, где запущено приложение). Это критически важно для работы с чувствительными данными.

    Автономность: После загрузки модель может работать без доступа в интернет.

Почему именно facebook/bart-large-cnn? (Для английского языка)

    "Золотой стандарт" для суммаризации: Эта модель — один из самых известных и хорошо зарекомендовавших себя инструментов именно для задачи abstractive summarization (генерации нового, связного текста, а не простого выдергивания предложений).

    Специализированная тренировка: Она была специально дообучена на огромном датасете новостных статей и их заголовков (CNN/DailyMail), что делает её идеально подходящей для генерации кратких выжимок из статей и документов.

    Оптимальный баланс: Модель достаточно "большая" (large), чтобы генерировать качественные саммари, но при этом не настолько огромная, чтобы её запуск был невозможен на потребительском железе (например, на GPU с 8-16 ГБ VRAM или даже на CPU, хоть и медленно).

    Соответствие заданию: Это одна из моделей, прямо рекомендованных в задании.

Почему именно cointegrated/rut5-base-multitask? (Для русского языка)

    Поддержка русского языка: Модель BART плохо работает с русским языком. rut5 — это одна из лучших общедоступных моделей семейства T5 для русского языка.

    Архитектура T5 (Text-to-Text Transfer Transformer): Модели T5 очень гибкие. Они решают любую задачу как "преобразование текста в текст". Добавляя префикс к входному тексту (в коде это summarize: ), мы даем модели понять, какую именно задачу нужно выполнить.

    Качество для русского языка: rut5-base-multitask — это проверенная сообществом модель, которая хорошо справляется с различными задачами, включая суммаризацию, для русского языка.

2. Модель через API (llama3-70b-8192 через Groq)

Это большая языковая модель, доступ к которой осуществляется через интернет-запрос (API).

Почему она нужна?

    Высочайшее качество: Модели вроде Llama 3 70B на порядки мощнее и "умнее" локальных. Они генерируют гораздо более осмысленные, связные и человекоподобные саммари. Они лучше улавливают контекст, логику и скрытые связи в тексте.

    Скорость (специфика Groq): Сервис Groq известен своей феноменальной скоростью генерации текста благодаря специализированным чипам (LPU). Это позволяет получать результат от огромной 70-миллиардной модели почти мгновенно, что сильно улучшает пользовательский опыт.

    Большой контекстный лимит: У модели llama3-70b-8192 контекстное окно в 8192 токена, что позволяет обрабатывать большие "куски" текста за один раз. Это повышает качество промежуточных саммари в стратегии Map-Reduce.

    Нет требований к железу: Вся вычислительная нагрузка ложится на серверы Groq. Пользователю не нужен мощный компьютер.

Почему именно Llama 3 через Groq?

    Соответствие принципу задания: Задание просило использовать mistral-7b-instruct через API. Llama 3 70B — это еще более мощная и современная модель, чем Mistral 7B. Использование её через API полностью реализует этот пункт задания.

    Демонстрация гибкости: Этот выбор показывает умение работать с внешними сервисами, отправлять API-запросы и обрабатывать ответы.
